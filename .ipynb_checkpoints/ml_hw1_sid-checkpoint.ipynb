{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b6c4513-d559-46c8-aa5b-c7f5d113c3fd",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5fce04-6ce2-4bb7-a91c-4b2a2baeb73a",
   "metadata": {},
   "source": [
    "Answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12f19f6-29b3-4eb3-b697-bff6ff97d462",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6293cc-2e8e-426a-a2a5-b6fda562435c",
   "metadata": {},
   "source": [
    "Answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b0036c-d977-4da0-ba26-beeb9ae55456",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ec4d7e-c710-40da-bf2f-7c7c13457e19",
   "metadata": {},
   "source": [
    "a.\n",
    "\n",
    "The probability of a point from sample space falling into the gap is E.\n",
    "The probability of a point falling outside the gap is 1 - E.\n",
    "The probability of N points falling outside the gap is (1 - E)^N.\n",
    "\n",
    "We know that (1 - E) = 1 + E + E^2/2! + E^3/3! + ... = e^-E\n",
    "\n",
    "Therefore, (1 - E)^N  = e^-EN = delta\n",
    "\n",
    "-EN ln e = ln delta\n",
    "\n",
    "N = -ln delta/E\n",
    "\n",
    "b.\n",
    "\n",
    "c.\n",
    "\n",
    "1 - delta = 99% => delta = 0.01\n",
    "E = 5% = 0.05\n",
    "\n",
    "N = -ln (0.01) / 0.05 = 92"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b84ea56-abf8-4f45-8838-92d77c46fd8f",
   "metadata": {},
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f133deb-2ca6-4933-af27-805d1d9b06af",
   "metadata": {},
   "source": [
    "Scikit-learn uses this formula to calculate idf:\n",
    "\n",
    "idf = log(n_samples / df(w)) + 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "552fdad4-653c-4117-b297-63b48163dadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d162b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['The fat cat sat in the hat',\n",
    "             'The cat destroyed the hat',\n",
    "             'The hat is too big',\n",
    "             'The fat cat likes the big cat',\n",
    "            'The big dog likes fat people']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0cdebfc-4b00-4b6a-a001-f30ae4aa9723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0],\n",
       " [0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 2, 0, 0, 1, 0, 0, 1, 0, 0, 0],\n",
       " [1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = ['big', 'cat', 'destroyed', 'dog', 'fat', 'hat', 'in', 'likes', 'people', 'sat', 'too']\n",
    "\n",
    "sentences = ['The fat cat sat in the hat',\n",
    "             'The cat destroyed the hat',\n",
    "             'The hat is too big',\n",
    "             'The fat cat likes the big cat',\n",
    "            'The big dog likes fat people']\n",
    "\n",
    "vocab_mat = []\n",
    "\n",
    "## bag-of-words encoding\n",
    "\n",
    "for s in sentences:\n",
    "    vocab_li = [0]*11\n",
    "    words = s.split(' ')\n",
    "    for w in words:\n",
    "        if w in vocabulary:\n",
    "            vocab_li[vocabulary.index(w)] += 1\n",
    "    vocab_mat.append(vocab_li)\n",
    "\n",
    "vocab_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e51b6d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6094379124341003\n",
      "1.6094379124341003\n",
      "1.6094379124341003\n",
      "1.6094379124341003\n",
      "1.6094379124341003\n",
      "1.6094379124341003\n",
      "1.6094379124341003\n",
      "1.6094379124341003\n",
      "1.6094379124341003\n",
      "1.6094379124341003\n",
      "1.6094379124341003\n",
      "1.6094379124341003\n",
      "0.9162907318741551\n",
      "1.6094379124341003\n",
      "1.6094379124341003\n",
      "1.6094379124341003\n",
      "1.6094379124341003\n",
      "1.6094379124341003\n",
      "1.6094379124341003\n",
      "1.6094379124341003\n"
     ]
    }
   ],
   "source": [
    "idf_mat = []\n",
    "for v in vocab_mat:\n",
    "    for i in v:\n",
    "        if i != 0:\n",
    "            print(math.log((len(vocab_mat))/i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9386927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
