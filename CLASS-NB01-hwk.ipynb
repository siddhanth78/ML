{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81bcccb0",
   "metadata": {},
   "source": [
    "# Homework: Sentiment analysis of product reviews (Part 1)\n",
    "\n",
    "\n",
    "In this notebook you will explore logistic regression and feature engineering with scikit-learn functions. You will use product review data from Amazon to predict whether the sentiment about a product, inferred from its review, is positive ($+1$) or negative ($-1$). \n",
    "\n",
    "Even though more sophisticated approaches exist, such as tf-idf (discussed in module 1), for simplicity we'll use a bag-of-words representation as our feature matrix. If you need to review, feature extraction on text data was discussed in the first module of the course.\n",
    "\n",
    "Your job is to do the following:\n",
    "* Perform some basic feature engineering to deal with text data\n",
    "* Use scikit-learn to create a vocabulary for a corpus of reviews\n",
    "* Create a bag of words representation based on the vocabulary shared by the reviews\n",
    "* Train a logistic regression model to predict the sentiment of product reviews.\n",
    "* Inspect the weights (coefficients) of a trained logistic regression model.\n",
    "* Make a prediction (both class and probability) of sentiment for a new product review.\n",
    "* Given the computed weights, predictors and ground truth labels, write a function to compute the accuracy of the model.\n",
    "* Inspect the coefficients of the logistic regression model and interpret their meanings.\n",
    "* Compare multiple logistic regression models.\n",
    "\n",
    "As usual, we import a few libraries we need. Later, you'll need to import more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daa0df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# use WIDER CANVAS:\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325657e0",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "We will use a dataset consisting of Amazon baby product reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7f0ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_csv('~/data/amazon_baby.gz')\n",
    "print('We will work with',len(products),'reviews of baby products')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b712d03",
   "metadata": {},
   "source": [
    "Let's take a peek at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4654771",
   "metadata": {},
   "outputs": [],
   "source": [
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21c8891",
   "metadata": {},
   "source": [
    "Let's examine the second review. In Pandas you can access entries by index number. Indices usually start at 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa92f3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "an_entry=1\n",
    "for col in products.columns:\n",
    "    print(f'{col.upper()}: {products.iloc[an_entry][col]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ae62a5",
   "metadata": {},
   "source": [
    "## Build word count vector for each review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab3f855",
   "metadata": {},
   "source": [
    "First, we perform two simple data transformations:\n",
    "\n",
    "1. Remove punctuation using [Python's built-in](https://docs.python.org/2/library/string.html) string functionality.\n",
    "2. Transform the reviews into a bag-of-words representation using a countvectorizer.\n",
    "\n",
    "*Note*. For the sake of simplicity, we replace all punctuation symbols (e.g., !, &, :, etc.) by blanks. A better approach would preserve composite words such as \"would've\", \"hasn't\", etc. If interested, see [this page](https://www.nltk.org/_modules/nltk/tokenize/treebank.html)\n",
    "for scripts with better ways of handling punctuation.\n",
    "\n",
    "Make sure to look up the details for `maketrans`, a method of the `str` class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bdf0c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# These are the symbols we will replace\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b928249c",
   "metadata": {},
   "source": [
    "***Question 1.*** Complete a function `remove_punctuation(text)` to replace punctuation symbols by blanks in its `text` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f852e8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "import string \n",
    "def remove_punctuation(text):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d4742d",
   "metadata": {},
   "source": [
    "Let's test your function on the sample review displayed earlier, but first, we create a clean corpus of reviews without punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a83928",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_no_punctuation = products['review'].apply(remove_punctuation)\n",
    "print(review_no_punctuation[an_entry])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2945b1",
   "metadata": {},
   "source": [
    "## Create the feature matrix X\n",
    "We need a feature matrix with one row for each review. Each row uses a bag-of-word representation on a vocabulary built on the entire corpus of reviews. This task can be easily carried out using the `CountVectorizer` class of sklearn. \n",
    "\n",
    "The vectorizer works by creating a vocabulary (set of words) in a corpus, tokenizing the words in the vocabulary (assigning a unique integer to each word), and creating a bag-of-words representation for each document (review) in the corpus. The integers assigned to the words in the vocabulary become positions in a feature vector that counts the number of occurrences of each particular word. Since in practice feature vectors are huge, a compressed row matrix (`csr_matrix`) is used for each row (see scipy's Compressed Sparse Row matrix for more information).\n",
    "\n",
    "***Question 2.***\n",
    "- Create an instance `cv` of the CountVectorizer class that can remove three types of words: *stop words* (listed below), words that appear in only one review, and words that appear in more than 60% of the reviews.\n",
    "- Using the `fit` function, tokenize the words that were not removed from the clean corpus of reviews. As a side effect, this step creates a dictionary (`vocabulary_`) that maps words to integer positions.\n",
    "- Create a bag-of-words csr_matrix (feature vector) for each review and store it in an additional column `word_count_vec` of the products dataframe.\n",
    "\n",
    "Use the following list of stop words: ['you','he','she','they','an','the','and','or','in','on','at','is','was','were','am','are']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abbf228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "...\n",
    "products['word_count_vec'] = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95963a07",
   "metadata": {},
   "source": [
    "***Question 3.*** How big are the feature vectors? This, of course, is the same for all samples. What are the feature vector locations of the words 'great' and 'poor'? *Hint.* The vocabulary is a Python dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b657bd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47d60f8",
   "metadata": {},
   "source": [
    "**Question 4.** Print the review of the 28th entry in `products` (remember 0-indexing!). Write code to answer the following questions:\n",
    "- How many distinct words from the dictionary appear in the cleaned review? \n",
    "- How many times does the word 'book' appear in the review? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac1d27d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f892297",
   "metadata": {},
   "source": [
    "## Extract sentiments\n",
    "\n",
    "We will **ignore** all reviews with *rating = 3*, under the assumption that they usually express a neutral sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0362805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = products[products['rating'] != 3]\n",
    "print(f'We are left with {len(products)} reviews with strong sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf632104",
   "metadata": {},
   "source": [
    "***Question 5.*** Consider reviews with a rating of 4 or higher to be *positive* reviews, and ones with rating of 2 or lower to be *negative*. Create a sentiment column, using $+1$ for the positive class label and $-1$ for the negative class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d412fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899dd03c",
   "metadata": {},
   "source": [
    "The dataset now contains an extra column called **sentiment** which is either positive (+1) or negative (-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aa75b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the new column\n",
    "products[['name','rating','sentiment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2290c3b",
   "metadata": {},
   "source": [
    "## Split data into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58187e73",
   "metadata": {},
   "source": [
    "Let's perform a 80-20 train/test split of the data. We'll use `random_state=0` so that everyone gets the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c886b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a53c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = products.sample(frac=.8, random_state=0)\n",
    "test_data = products.drop(train_data.index)\n",
    "print(f'We will use N={len(train_data)} training samples')\n",
    "print(f'and {len(test_data)} testing samples')\n",
    "print(f'Total samples: {len(products)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a80220",
   "metadata": {},
   "source": [
    "## Train a sentiment classifier with logistic regression\n",
    "\n",
    "We will now use logistic regression to create a sentiment classifier on the training data. This model will use the column **word_count_vec** as a feature and the column **sentiment** as the target.\n",
    "\n",
    "***Question 6.*** Create a logistic regression model called `sentiment_model` with scikit-learn (similar to the one in the class demo) with $L_2$-regularization and $C=100$ penalty. You will need to extract a feature matrix `X_train` and vector of true labels `y_train` from your training data.  To create the feature matrix X_train you will need to stack the rows of bag-of-words into a single matrix (you may want to check the function `vstack` in scipy).\n",
    "\n",
    "*Note:* This may take a while on a big trainings set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4408dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ea10a5",
   "metadata": {},
   "source": [
    "X_train should now be a *compressed* feature matrix of size $N\\times d$, where $d$ is the size of the vocabulary. Let's check it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612c10e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X_train))\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3237bd05",
   "metadata": {},
   "source": [
    "Now that we have fitted the model, we can extract the weights (coefficients) as a dictionary as follows:\n",
    "\n",
    "***Question 7.*** Extract the weights of the words and store them in a dictionary `word_coef` that maps feature names (words) to coefficients. *Hint.* You can get the feature names using your vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79434f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Create an empty dictionary to store the word to coefficient mapping\n",
    "word_coef = {}\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248cd7c9",
   "metadata": {},
   "source": [
    "There are thousands of coefficients in the model. Recall from the lecture that positive weights $w_j$ correspond to favorable reviews, while negative weights correspond to negative ones. \n",
    "\n",
    "Let's examime the coefficients of a few features as a sanity check. Did you get what you expected?\n",
    "\n",
    "***Question 8.*** Find the coefficients of the following words: 'awesome', 'good', 'great', 'awful', 'terrible', 'poor'. How many words got a coefficient inconsistent with its meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1055e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123b06fc",
   "metadata": {},
   "source": [
    "***Question 9.*** Fill in the following block of code to compute the number `num_pos_weights` of positive (>0) weights and the number `num_neg_weights` of negative (<=0) weights. Print both counts and verify that they add to the total number of coefficients you computed earlier in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac1e48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dc2120",
   "metadata": {},
   "source": [
    "## Making predictions with logistic regression\n",
    "\n",
    "Now that a model is trained, we can make predictions on the **test data**. In this section, we will explore this in the context of 8 examples in the test dataset.  We refer to this set of examples as the **sample_test_data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef1b024",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_data = test_data.iloc[90:98]\n",
    "sample_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52b366e",
   "metadata": {},
   "source": [
    "Let's dig deeper into the rows of the **sample_test_data**. Here are the ratings and reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91165f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sample_test_data)):\n",
    "    print('\\nrating:',sample_test_data.iloc[i]['rating'])\n",
    "    print('review:\\n',sample_test_data.iloc[i]['review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12260c8",
   "metadata": {},
   "source": [
    "We will now make a **class** prediction for our **sample_test_data**. We hope that `sentiment_model` predicts **+1** if the true sentiment is positive and **-1** if the true sentiment is negative. Recall from lecture that the score $z$ for the logistic regression model  is defined as:\n",
    "$$z_i = \\mathbf{w}\\cdot \\mathbf{x}_i$$ \n",
    "\n",
    "where $\\mathbf{x}_i$ represents the features (word counts) for sample $i$ and the corresponding score is a number in the range $(-\\infty,\\infty)$. We will write some code to obtain the **scores** using sklearn.\n",
    "\n",
    "***Question 10.*** Using your model's `decision_function`, compute the **scores** (these are the $z$-values) of the reviews in `sample_test_data` and print the true sentiment. How many scores are compatible with the true sentiment values? Interpret your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00993d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "scores = []\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef05132",
   "metadata": {},
   "source": [
    "### Predicting sentiment\n",
    "\n",
    "These scores can now be used to make class predictions, as follows:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "      +1 & \\mathbf{w} \\cdot \\mathbf{x}_i > 0 \\\\\n",
    "      -1 & \\mathbf{w}\\cdot \\mathbf{x}_i \\leq 0 \\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$\n",
    "\n",
    "***Question 11.*** Using scores, write python code to compute and print $\\hat{y}$, the class predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4515d126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc30bc1",
   "metadata": {},
   "source": [
    "*Sanity check*. Run the following code to check whether the class predictions obtained using your code are the same as those produced by sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd5bfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Class predictions according to sklearn:\")\n",
    "print(sentiment_model.predict(sp.vstack(sample_test_data['word_count_vec'].values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76b82c8",
   "metadata": {},
   "source": [
    "### Probability predictions\n",
    "\n",
    "Recall from the lectures that we can also calculate the probabilities that $y=+1$ from the scores using:\n",
    "$$\n",
    "\\mbox{Pr}(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1+e^{-\\mathbf{w}\\cdot\\mathbf{x}_i}}\n",
    "$$\n",
    "\n",
    "***Question 12.*** Using the variable `scores` computed previously, write a single line of code to estimate the probability that a sentiment is positive using the above formula. Print the results. For each row, the probabilities should be a number in $[0, 1]$. Of the eight data points in **sample_test_data**, which one, classified as positive, has the *lowest probability* of being classified as a positive review? Was this prediction correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c481ba76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442e132f",
   "metadata": {},
   "source": [
    "***Question 13.*** Now compute estimated probabilities with sklearn by using the function `predict_proba` on your model.\n",
    "\n",
    "*Sanity check*: Make sure your probability predictions match the ones obtained from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bc8021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f688c4",
   "metadata": {},
   "source": [
    "### Find the most positive and most negative reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3432c04",
   "metadata": {},
   "source": [
    "We now turn to examining the test dataset, **test_data** and, for faster performance, use sklearn to form predictions on all of the test data points.\n",
    "\n",
    "***Question 14.*** Using the `sentiment_model`, find the 20 reviews in the entire **test_data** with the **highest probability** of being classified as a **positive review**. We refer to these as the \"most positive reviews.\" Recall that you can make probability predictions by using `.predict_proba` and you can select the $n$ largest values of a frame with the function `nlargest`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e073a639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cca863",
   "metadata": {},
   "source": [
    "***Question 15.***\n",
    "Now, repeat this exercise to find the 20 \"most negative reviews\" in the test data. Recall that a review is considered negative if it has a low probability of being positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836c0565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4f7cc3",
   "metadata": {},
   "source": [
    "## Compute accuracy of the classifier\n",
    "\n",
    "We will now evaluate the accuracy of the trained classifier. Recall that the accuracy is given by\n",
    "\n",
    "\n",
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{# correctly classified examples}}{\\mbox{# total examples}}\n",
    "$$\n",
    "\n",
    "***Question 16.*** Write a function `get_classification_accuracy` that takes in a model, a dataset, the true labels of the data set, and returns the accuracy of the model measured on the given data set.\n",
    "\n",
    "You will need to:\n",
    "1. Use the trained model to compute class predictions (you can use the `predict` method)\n",
    "2. Count the number of data points when the predicted class labels match the true labels (the ground truth).\n",
    "3. Divide the total number of correct predictions by the total number of data points in the dataset.\n",
    "\n",
    "Complete the function below to compute the classification accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9c4fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def get_classification_accuracy(model, data, true_labels):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7002c88b",
   "metadata": {},
   "source": [
    "Now, let's check the accuracy of our sentiment_model.\n",
    "\n",
    "***Question 17.*** What is the accuracy of the **sentiment_model** on the **training_data** and on the **test_data**? Round your answer to 4 decimal places. What does this tell you about the quality of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8995bf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aa58df",
   "metadata": {},
   "source": [
    "There are lots of words in the model we trained above. We want to determine which ones are the most important.\n",
    "\n",
    "***Question 18.*** Write code to find the 10 most positive and the 10 most negative weights in our learned model. Print both the feature name and the corresponding weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3379a15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be82218b",
   "metadata": {},
   "source": [
    "## Learn another classifier with fewer words\n",
    "\n",
    "We will now train a simpler logistic regression model using only a subset of words that occur in the reviews. For this portion of the assignment, we selected 18 words to work with. These `significant_words` are shown in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef2d5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves','wonderfully','lifesaver',\n",
    "      'well', 'broke', 'less', 'waste', 'disappointed', 'unusable',\n",
    "      'work', 'money', 'return']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ebcb70",
   "metadata": {},
   "source": [
    "***Question 19.*** Create a new instance of CountVectorizer which will create a feature vector out of a given string based on instances of our significant words in the string. First, you will build the small vectorizer by specifying its vocabulary in the constructor function `CountVectorizer`. Then, you'll transform each review into a bag-of-words using this new vectorizer, placing the new vectors in the column **subset_word_count_vec**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212624d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dab95a",
   "metadata": {},
   "source": [
    "Add the new column  to our training and testing DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9add18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['word_count_subset_vec'] = products['word_count_subset_vec']\n",
    "test_data['word_count_subset_vec'] = products['word_count_subset_vec']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03372f2",
   "metadata": {},
   "source": [
    "Let's see what an example of the training dataset looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d322b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_entry=4\n",
    "print(train_data.iloc[an_entry]['review'])\n",
    "train_data.iloc[an_entry]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c2d3d9",
   "metadata": {},
   "source": [
    "Since we are only working with a subset of the available words, only a few `significant words` will be present in this review."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca049ff",
   "metadata": {},
   "source": [
    "## Train a logistic regression model on a subset of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a2b533",
   "metadata": {},
   "source": [
    "***Question 20.*** Build a classifier with **word_count_subset_vec** as the feature and **sentiment** as the target, using the same training parameters as for the full model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce40a79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddc91af",
   "metadata": {},
   "source": [
    "Now, we will inspect the weights (coefficients) of the **simple_model**.\n",
    "\n",
    "***Question 21.*** Just as you did in **Question 7**, extract the weights of the words and store them in a dictionary `word_coef` that maps feature names (words) to coefficients. Print the words to coefficient mapping, sorting the coefficients (in descending order) by the **value** to obtain the coefficients with the most positive effect on the sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd9227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf38209b",
   "metadata": {},
   "source": [
    "***Question 22.*** Consider the coefficients of **simple_model**. There should be 19 of them, an intercept term + one for each word in **significant_words**. How many of the coefficients (corresponding to the **significant_words** and *excluding the intercept term*) are positive for the `simple_model`? Write a single line of code to compute the answer (do not compute it by hand!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3db25e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb908439",
   "metadata": {},
   "source": [
    "***Question 23***: Are the positive words in the **simple_model** (let us call them `positive_significant_words`) also positive words in the **sentiment_model**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe60da9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35461e9",
   "metadata": {},
   "source": [
    "## Comparing models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835cf2e4",
   "metadata": {},
   "source": [
    "We will now compare the accuracy of the **sentiment_model** and the **simple_model** using the `get_classification_accuracy` method you implemented above.\n",
    "\n",
    "***Question 24.*** Compute the classification accuracy of the **sentiment_model** and of the **simple_model** on the **train_data**. Which model (**sentiment_model** or **simple_model**) has higher accuracy on the training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7fc9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9d9d8a",
   "metadata": {},
   "source": [
    "Now, we will repeat this exercise on the **test_data**. Start by computing the classification accuracy of the **sentiment_model** on the **test_data**:\n",
    "\n",
    "***Question 25.*** Compute the classification accuracy of the sentiment_model and of the simple_model on the test_data. Which model (sentiment_model or simple_model) has higher accuracy on the testing set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed17695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e80728f",
   "metadata": {},
   "source": [
    "## Baseline: Majority class prediction\n",
    "\n",
    "It is quite common to use the **majority class classifier** as the a baseline (or reference) model for comparison with your classifier model. The majority classifier model predicts the majority class for all data points. At the very least, you should comfortably beat the majority class classifier, otherwise, the model is (usually) pointless.\n",
    "\n",
    "***Question 26.*** Write a function `compute_majority_classifier(data,label)` that returns a majority classifier for the column `label` of frame `data` (***yes***, *I am asking you to write a function that returns a function*). You may assume that the labels are numeric $+1$ or $-1$. Test it using the sentiment of **train_data**. What does the majority classifier return in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fe4177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f616822b",
   "metadata": {},
   "source": [
    "***Question 27.*** Compute the accuracy of the majority classifier on the **test_data**. Round your answer to two decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6ef5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df2c7ba",
   "metadata": {},
   "source": [
    "***Question 28.*** Is the **sentiment_model** definitely better than the majority class classifier (the baseline)? Based on the gathered information, does the **sentiment_model** suffer from high bias or from high variance? What else would you try to improve performance? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b85625",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
